{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83dd584a-eadb-49af-8e08-f5fc92de08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from itertools import combinations\n",
    "from operator import concat\n",
    "import igraph\n",
    "import Surfaces\n",
    "# import TwoMapper\n",
    "from gtda.mapper import (\n",
    "    CubicalCover,\n",
    "    make_mapper_pipeline,\n",
    "    Projection,\n",
    "    plot_static_mapper_graph,\n",
    "    plot_interactive_mapper_graph,\n",
    "    MapperInteractivePlotter,\n",
    "    nerve\n",
    ")\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import reduce\n",
    "\n",
    "from Giotto2Mapper import (two_dim_nerve, two_mapper)\n",
    "import sympy as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece9ce0-937c-4746-b6bc-e32637bb8e10",
   "metadata": {},
   "source": [
    "## GOALS.\n",
    "\n",
    "We wish to define a novel new higher dimensional cover for Mapper. \n",
    "\n",
    "Input: $f(X)$ which is the image of our data set under some continuous map $f\\colon X \\to \\mathbb{R}^n$\n",
    "1. [x] Need to identify what dimension our image is.\n",
    "2. [x] Embed our image into $\\mathbb{R}^{n+1}$ via the map $v = (v_1,...,v_n)\\mapsto (v_1,...,v_n, -\\sum_{i=1}^n v_n)$]\n",
    "3. [x] Find bounding box for our image $\\iota \\circ f (X)$\n",
    "4. [x] Choose generator matrix $M$ associated with $A_n^*$.\n",
    "-- Note we have special $M$ for $n=2,3$.\n",
    "5. [x] Find scaling coefficient $c$ and scale lattice $cM$.\n",
    "-- Note we will define $c = \\min_{i}\\lceil\\frac{1}{n-intervals}(M_i - m_i)\\rceil$.\n",
    "6. [ ] Find which data points lie in spheres of radius $cR(1+g)$ cenetered at lattice points in the boudning box.\n",
    "-- Note $R$ is the $\\textit{covering radius}$ of $A_n^*$ and $g$ is the `perc_overlap`.\n",
    "7. [ ] Use this mask to define our clusters.\n",
    "\n",
    "Our previous coverclass will be a large influence in how $A_n^*$ our constructed.\n",
    "\n",
    "**It is important to validate that 1-dimensional $A_n^*$ is equivalent to 1-dimensional interval cover**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4bc8cb49-0d96-44e5-abe9-2143e43e2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from gtda.utils.validation import validate_params\n",
    "from gtda.utils.intervals import Interval\n",
    "import warnings\n",
    "from gtda.mapper.utils._cover import _check_has_one_column, _remove_empty_and_duplicate_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5d2727ba-dfb7-433d-843f-c1fcc477e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatticeCover(BaseEstimator, TransformerMixin):\n",
    "    # Parameters\n",
    "    _hyperparameters = {\n",
    "        'n_intervals': {'type': int, 'in': Interval(1, np.inf, closed='left')},\n",
    "        'overlap_frac': {'type': float, 'in': Interval(0, 1, closed = 'neither')},\n",
    "        'special': {'type': bool}\n",
    "    }\n",
    "    ''' \n",
    "    Attributes\n",
    "    -----------\n",
    "    TBD:\n",
    "    'left limits'\n",
    "    'right limits'\n",
    "    'ball centers (lattice points)'\n",
    "    'cover radius'\n",
    "    'dim'\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_intervals = 10, overlap_frac = 0.3, special = False):\n",
    "        self.n_intervals = n_intervals\n",
    "        self.overlap_frac = overlap_frac\n",
    "        self.special = special\n",
    "        \n",
    "    def _fit(self, X):\n",
    "        self.dim = _check_dim(X)\n",
    "        if self.special is False:\n",
    "            X = _hyperplane_embed(X)\n",
    "        self.left_limits_, self.right_limits_ = _find_bounding_box(X,\n",
    "                                                                   self.dim,\n",
    "                                                                   self.n_intervals, \n",
    "                                                                   self.special\n",
    "                                                                  )\n",
    "        self.ball_centers_, self.ball_radius_ = self._lattice_cover_limits(self.left_limits_,\n",
    "                                                                           self.right_limits_,\n",
    "                                                                           self.dim,\n",
    "                                                                           self.n_intervals,\n",
    "                                                                           self.overlap_frac,\n",
    "                                                                           self.special\n",
    "                                                                          )\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = check_array(X)\n",
    "        validate_params(self.get_params(), self._hyperparameters)\n",
    "        if self.overlap_frac <= 1e-8:\n",
    "            warmings.warm(\"`overlap_frac` is close to zero, \"\n",
    "                          \"which might cause numerical issues and errors.\",\n",
    "                          RuntimeWarning)\n",
    "        fitter = self._fit\n",
    "        return fitter(X)\n",
    "\n",
    "    def _transform_data(self, X):\n",
    "        data_bools = np.full((self.ball_centers_.shape[0]), False)\n",
    "        for i in range(X.shape[0]):\n",
    "            cover_check = np.linalg.norm(self.ball_centers_ - X[i], axis = 1) < self.ball_radius_\n",
    "            if np.any(cover_check):\n",
    "                data_bools = np.vstack([data_bools, cover_check])\n",
    "        return data_bools[1:]\n",
    "            \n",
    "    def _transform_centers(self, X):\n",
    "        cover_bools = np.full((X.shape[0],), False)\n",
    "        for i in range(self.ball_centers_.shape[0]):\n",
    "            cover_check = np.linalg.norm(X - self.ball_centers_[i], axis = 1) < self.ball_radius_\n",
    "            if np.any(cover_check):\n",
    "                cover_bools = np.vstack([cover_bools, cover_check])\n",
    "        data_bools = cover_bools.T\n",
    "        return data_bools[1:]\n",
    "        \n",
    "    def _transform(self, X):\n",
    "        if self.ball_centers_.shape[0] < X.shape[0]:\n",
    "            data_bools = self._transform_centers(X)\n",
    "        if X.shape[0] < self.ball_centers_.shape[0]:\n",
    "            data_bools = self._transform_data(X)\n",
    "        return data_bools\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        check_is_fitted(self)\n",
    "        Xt = check_array(X)\n",
    "        Xt = self._transform(Xt)\n",
    "        Xt = _remove_empty_and_duplicate_intervals(Xt)\n",
    "        return Xt\n",
    "\n",
    "    def _fit_transform(self, X):\n",
    "        if self.special:\n",
    "            Xt = self._fit(X)._transform(X)\n",
    "        if self.special is False:\n",
    "            Xt = self._fit(X)._transform(_hyperplane_embed(X))\n",
    "        return Xt\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        Xt = check_array(X)\n",
    "        validate_params(self.get_params(), self._hyperparameters)\n",
    "        Xt = self._fit_transform(Xt)\n",
    "        Xt = _remove_empty_and_duplicate_intervals(Xt)\n",
    "        return Xt\n",
    "\n",
    "    def _check_dim(X):\n",
    "        if X.shape[1] > 8:\n",
    "            warnings.warn(\"Using an incredibly high dimensional (dim {X.shape[1]}) cover?? Dont.\")\n",
    "        return X.shape[1]\n",
    "    \n",
    "    'Embeds our data X\\sub R^{dim} \\righthookarrow R^{dim+1}'\n",
    "    def _hyperplane_embed(X):\n",
    "        embed = -np.sum(X,axis=1).T\n",
    "        return np.c_[X, embed]\n",
    "    'Finds bounds for each coordinate over data set X'\n",
    "    'Outputs a (dim+1,2) array'\n",
    "    def _find_bounding_box(X, dim, n_intervals, special=False):\n",
    "        if special and (dim not in {2,3}):\n",
    "            raise ValueError(f'We only have special lattice representations in dimensions 2 and 3.')\n",
    "        coord_array = np.zeros((dim+1,2)) # Embed image into R^{dim+1}\n",
    "        for i in range(dim+1):\n",
    "            coord_array[i,0] = np.min(X[:,i]) # Minimum value in i-th coord\n",
    "            coord_array[i,1] = np.max(X[:,i]) # Maximum value in i-th coord\n",
    "        only_one_pt = all( _ == coord_array.ravel()[0] for _ in coord_array.ravel())\n",
    "        if only_one_pt and n_intervals > 1:\n",
    "            raise ValueError(\n",
    "                f\"Only one unique filter value found, cannot fit\"\n",
    "                f\"{n_intervals} > 1 intervals.\")\n",
    "        if special: # We have special representations for A* in dimensions 2 and 3.\n",
    "            return coord_array[:dim, 0], coord_array[:dim, 1]\n",
    "        else:\n",
    "            return coord_array[:,0], coord_array[:,1]\n",
    "\n",
    "    def _get_generator_matrix(dim, special=False):\n",
    "        if dim < 2:\n",
    "            raise ValueError(f'Lattice Cover can only be computed with filters with dimension 2 or greater, {dim} entered')\n",
    "            ## CHANGE ABOVE TO WORK FOR DIM 1 ##\n",
    "        if dim == 2 and special:\n",
    "            basis_vectors = np.array([1,0,-1/2,np.sqrt(3)/2]).reshape((2,2))\n",
    "        if dim == 3 and special:\n",
    "            basis_vectors = np.array([2,0,0,0,2,0,1,1,1]).reshape((3,3))\n",
    "        else:\n",
    "            basis_vectors = np.zeros((dim, dim+1))\n",
    "            basis_vectors[dim-1, 0] = -dim/(dim+1)\n",
    "            basis_vectors[dim-1, dim] = 1/(dim+1)\n",
    "            for i in range(dim-1):\n",
    "                basis_vectors[i,0] = 1\n",
    "                basis_vectors[i,i+1] = -1\n",
    "                basis_vectors[dim-1,i+1] = 1/(dim+1)\n",
    "        generator_matrix = np.asmatrix(basis_vectors)\n",
    "        return generator_matrix\n",
    "\n",
    "    ## Taken from:\n",
    "    ## https://stackoverflow.com/questions/11144513/cartesian-product-of-x-and-y-array-points-into-single-array-of-2d-points\n",
    "    def cartesian_product(arrays):\n",
    "        la = len(arrays)\n",
    "        dtype = np.result_type(*arrays)\n",
    "        arr = np.empty([len(a) for a in arrays] + [la])\n",
    "        for i, a in enumerate(np.ix_(*arrays)):\n",
    "            arr[...,i] = a\n",
    "        return arr.reshape(-1, la)\n",
    "\n",
    "    @staticmethod\n",
    "    def _lattice_cover_limits(left_limits, right_limits, dim, n_intervals, overlap_frac, special):\n",
    "        generating_matrix = _get_generator_matrix(dim, special)\n",
    "        cover_radius = np.sqrt(dim * (dim + 2)/(12* (dim + 1)))\n",
    "        ldim = generating_matrix.shape[1]\n",
    "        assert left_limits.shape[0] == right_limits.shape[0] == ldim\n",
    "        bound_vector = np.abs(right_limits - left_limits)\n",
    "        scale = np.max([np.max(bound_vector/n_intervals), 1])\n",
    "        #print('c', scale)\n",
    "        # Create bounds for lattice points\n",
    "        scaled_min_bound, scaled_max_bound = np.zeros(dim), np.zeros(dim)\n",
    "        scaled_min_bound[:dim-1] = np.asarray([np.floor((left_limits[dim] - right_limits[j+1])/scale) for j in range(dim-1)])\n",
    "        scaled_min_bound[dim-1] = np.floor((ldim) * left_limits[dim] / scale)\n",
    "        scaled_max_bound[:dim-1] = np.asarray([np.ceil((right_limits[dim] - left_limits[j+1])/scale) for j in range(dim-1)])\n",
    "        scaled_max_bound[dim-1] = np.ceil((ldim) * right_limits[dim] / scale)\n",
    "        xi_coord_arrays = [np.arange(start = scaled_min_bound[k], stop = scaled_max_bound[k], step = 1) for k in range(dim)]\n",
    "        xi_vectors = cartesian_product(xi_coord_arrays) # all possible integer vectors to generate lattice points\n",
    "        #print(xi_vectors.shape)\n",
    "        lattice_points = (scale * xi_vectors @ generating_matrix).getA()\n",
    "        scaled_cover_radius = scale * cover_radius * (1 + overlap_frac) # radius for balls at each lattice point\n",
    "        return lattice_points, scaled_cover_radius                                                                        \n",
    "    #TO BE CONTINUED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "03ab826c-8a80-4e49-802a-7b4d7c99d616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1: [True, False, False], 3: [False, True, True], 4: [False, False, True]}\n",
    "y = [None] * 4\n",
    "del y[1:3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c51cd5d4-da14-4766-9b9e-f20335e3c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape((5,2))\n",
    "#b = np.c_(-np.sum(a,axis=1))\n",
    "b = np.c_[a, -np.sum(a,axis=1).T]\n",
    "bl, br = _find_bounding_box(b, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6b93ff57-6a53-4e4e-9fab-d766832c9b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b7014b00-74b6-4426-aef4-6183821f9aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1., -17.],\n",
       "       [  8.,   9.,  -1.],\n",
       "       [  0.,   1., -17.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, bl, br\n",
    "c = np.vstack([bl,br])\n",
    "np.vstack([c,bl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23e5eeec-da4f-4983-afa2-c4d30638436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 16.0\n",
      "(8, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.80521403245346,\n",
       " matrix([[ 6.66666667e-01,  6.66666667e-01, -1.33333333e+00],\n",
       "         [-1.11022302e-16,  1.00000000e+00, -1.00000000e+00],\n",
       "         [-6.66666667e-01,  1.33333333e+00, -6.66666667e-01],\n",
       "         [-1.33333333e+00,  1.66666667e+00, -3.33333333e-01],\n",
       "         [ 1.66666667e+00, -3.33333333e-01, -1.33333333e+00],\n",
       "         [ 1.00000000e+00,  5.55111512e-17, -1.00000000e+00],\n",
       "         [ 3.33333333e-01,  3.33333333e-01, -6.66666667e-01],\n",
       "         [-3.33333333e-01,  6.66666667e-01, -3.33333333e-01]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover, rad = _lattice_cover_limits(bl, br, 2, 1, 0.3, False)\n",
    "rad, cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9cdd1c76-3646-4c5e-8b25-9db6ecbd0609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[2, 3],\n",
       "        [2, 3],\n",
       "        [2, 3]],\n",
       "\n",
       "       [[4, 5],\n",
       "        [4, 5],\n",
       "        [4, 5]],\n",
       "\n",
       "       [[6, 7],\n",
       "        [6, 7],\n",
       "        [6, 7]],\n",
       "\n",
       "       [[8, 9],\n",
       "        [8, 9],\n",
       "        [8, 9]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.repeat([a], 3, axis=1).reshape((a.shape[0],3,2))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2bf8c59a-bb07-400f-92b7-30272a0b5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LatticeCover(n_intervals = 10, overlap_frac = 0.3, special = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9f29cd4a-30f3-4d5e-ace5-9674d45d0fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False,  True],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False,  True, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [ True, False, False, False, False]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "030ade10-5a37-43ae-b93b-e49b7ebe4185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a), len(l.fit_transform(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "75cff48f-9b6a-46cc-a81a-fc9fc9644438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False,  True],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False,  True, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [ True, False, False, False, False]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_remove_empty_and_duplicate_intervals(l.fit_transform(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bde100e9-052b-449a-98b2-27dda0a300c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(l.fit_transform(a), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d876d-eb00-4739-9fa5-e16eb8fe4b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "tda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
